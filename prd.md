# 数字 AI 劳务市场（MVP）PRD

## 1. 产品一句话定义

一个可以「像雇人一样雇 AI 干活」的 Web 应用。用户选择数字 AI 员工，提交任务，获得标准化交付物。

> 本质定位：AI 外包公司（不是聊天工具，不是 AI 工具集合）。

---

## 2. MVP 目标与边界

### 2.1 MVP 核心目标

* 验证：用户是否愿意把「具体工作任务」交给 AI 数字员工完成
* 验证：角色化、定价化、交付导向的 AI 是否比 Chat 更好用
* 验证：用户对「任务外包」心智模型的接受度

### 2.2 本阶段明确不做的事

* 不做用户创建 Agent
* 不做数字人市场 / 排行榜
* 不做复杂权限 / 团队
* 不做实时聊天
* 不做支付集成（可标价但暂不收费）

---

## 3. 目标用户

### 3.1 核心用户画像

* 独立开发者 / 创业者
* 产品经理 / 市场人员
* 需要「快速交付」而非「探索式聊天」的人
* 对 AI 有基本认知但不想调 Prompt 的人

### 3.2 用户真实动机

> "我不想再反复调 Prompt，我只想把活交出去。"

### 3.3 用户痛点

* 现有 AI 工具需要反复调试 Prompt
* 不确定 AI 能否完成特定任务
* 缺乏标准化的交付物
* 需要在多个 AI 工具间切换

---

## 4. 核心使用流程（唯一主路径）

### 4.1 主流程

1. 用户进入首页
2. 浏览数字 AI 员工列表
3. 选择一个数字员工（查看：他能干啥 / 不能干啥 / 价格）
4. 填写任务表单
5. 提交任务
6. 等待 AI 执行（同步 or 简单 loading）
7. 查看结构化交付结果
8. 复制 / 下载结果

### 4.2 详细用户旅程

| 阶段 | 用户行为 | 痛点 | 解决方案 |
|------|---------|------|---------|
| 发现 | 搜索"AI 帮我做 XX" | 不知道 AI 能做什么 | 清晰的能力列表 + 场景示例 |
| 选择 | 对比不同数字员工 | 不确定哪个适合 | 明确的适用场景 + 不适用场景 |
| 提交 | 填写任务需求 | 不知道该提供什么信息 | 结构化表单 + 示例填写 |
| 等待 | 等待 AI 处理 | 不知道进度 | 简单进度提示 |
| 获取 | 查看结果 | 结果不符合预期 | 标准化输出模板 + 重新提交 |

---

## 5. 数字 AI 员工设计（MVP 版）

### 5.1 数字员工数量

* 初始：3 个（最多不超过 5 个）

### 5.2 推荐首批角色

#### 角色 1：AI 商业分析师

* 适用场景：商业想法评估、方案分析
* 输入：
  * 想法描述（必填）
  * 行业 / 目标用户（可选）
* 输出：
  * 结构化分析报告（问题 / 机会 / 风险 / 建议）
* 价格标签：¥9.9 / 次（MVP 阶段免费）

#### 角色 2：AI 市场文案助理

* 适用场景：产品文案、推广文案
* 输入：
  * 产品介绍
  * 使用场景
  * 风格选择（理性 / 活泼 / 专业）
* 输出：
  * 3 套可直接使用的文案
* 价格标签：¥6.9 / 次（MVP 阶段免费）

#### 角色 3：AI 项目助理

* 适用场景：目标拆解、任务规划
* 输入：
  * 目标描述
  * 时间限制（可选）
* 输出：
  * 可执行 To-Do List（含优先级）
* 价格标签：¥8.9 / 次（MVP 阶段免费）

---

## 6. 数字员工的技术抽象（关键）

每个数字员工 = 一个「可执行劳务单元」

### 6.1 Agent 结构定义

```json
Agent {
  id: string,
  name: string,
  avatar: string,
  description: string,
  suitable_scenarios: string[],
  unsuitable_scenarios: string[],
  system_prompt: string,
  workflow_steps: [],
  input_schema: {},
  output_schema: {},
  output_template: string,
  price_label: string,
  estimated_time: string
}
```

### 6.2 Prompt 组成规则

最终 Prompt =

* System Prompt（角色与边界）
* 用户任务输入（表单）
* Workflow 约束（步骤 / 顺序）
* 输出模板（禁止自由发挥）

---

## 7. 功能需求（MVP 必须）

### 7.1 前端页面

#### 页面 1：首页 / 数字员工列表

* 显示：
  * 数字员工头像 / 名称
  * 能力简介（一句话）
  * 适用场景（2-3 个）
  * 价格标签（即使不收费也要显示）
  * 预计完成时间
* CTA：雇佣 TA
* 设计原则：
  * 卡片式布局
  * 突出「专业感」和「可信赖」
  * 避免过度拟人化

#### 页面 2：任务提交页

* 显示：
  * 数字员工信息卡片
  * 动态表单（基于 Agent input_schema）
  * 示例填写（可一键填充）
  * 提交按钮
  * 提示：交付内容说明
* 交互：
  * 表单验证（必填项提示）
  * 提交后显示 loading 状态
  * 预估等待时间提示

#### 页面 3：结果展示页

* 显示：
  * 任务信息回顾
  * AI 输出内容（结构化展示）
  * 操作按钮：复制 / 下载 / 重新提交
* 不支持编辑（保持"交付感"）
* 支持分享链接（可选）

#### 页面 4：任务历史（可选）

* 显示用户提交的所有任务
* 快速查看历史结果
* 支持重新执行相同任务

### 7.2 UI/UX 设计原则

* **专业感优先**：避免过度可爱或娱乐化
* **清晰的预期管理**：明确告知能做什么、不能做什么
* **降低决策成本**：提供示例、模板、默认值
* **强化交付感**：结果页面要有「完成」的仪式感
* **响应式设计**：支持移动端访问

### 7.3 错误处理与边界情况

* AI 执行失败：显示友好错误信息 + 重试按钮
* 输入不合规：实时表单验证 + 具体错误提示
* 超时处理：30 秒后显示「正在努力处理中」
* 空状态：首次访问时的引导提示
* 网络错误：离线提示 + 自动重连

---

## 8. 技术架构

### 8.1 技术栈推荐

#### 前端
* **框架**：Next.js 14（App Router）
* **UI 库**：Tailwind CSS + shadcn/ui
* **状态管理**：React Context / Zustand（轻量）
* **表单处理**：React Hook Form + Zod
* **HTTP 客户端**：Fetch API / Axios

#### 后端
* **框架**：Node.js + Express / Fastify
* **语言**：TypeScript
* **数据库**：PostgreSQL（结构化数据）+ Redis（缓存）
* **ORM**：Prisma
* **LLM 调用**：OpenAI SDK / Anthropic SDK

#### 基础设施
* **部署**：Vercel（前端）+ Railway / Render（后端）
* **监控**：Sentry（错误追踪）
* **日志**：Winston / Pino

### 8.2 系统架构图（文字描述）

```
用户浏览器
    ↓
Next.js 前端（Vercel）
    ↓
API Gateway（Express）
    ↓
    ├─→ Agent 配置服务（读取 Agent 定义）
    ├─→ 任务管理服务（创建、查询任务）
    ├─→ Prompt 组装服务（组装最终 Prompt）
    ├─→ LLM 调用服务（OpenAI / Claude）
    └─→ 结果存储服务（PostgreSQL）
```

### 8.3 核心 API 设计

#### GET /api/agents
* 功能：获取所有数字员工列表
* 响应：Agent[]

#### GET /api/agents/:id
* 功能：获取单个数字员工详情
* 响应：Agent

#### POST /api/tasks
* 功能：创建新任务
* 请求体：{ agent_id, input_data }
* 响应：{ task_id, status }

#### GET /api/tasks/:id
* 功能：获取任务结果
* 响应：Task（含 output_data）

#### GET /api/tasks
* 功能：获取用户任务历史
* 响应：Task[]

### 8.4 安全与认证

#### MVP 阶段
* **认证方式**：简单的 Session / JWT
* **用户识别**：浏览器指纹 + LocalStorage（无需注册）
* **数据隔离**：基于 session_id 隔离用户数据
* **API 限流**：每 IP 每小时最多 20 次请求

#### 后续考虑
* OAuth 登录（Google / GitHub）
* 邮箱注册 + 验证
* API Key 机制

### 8.5 数据隐私

* 用户输入数据仅用于 AI 处理
* 不与第三方共享（除 LLM 提供商）
* 提供数据删除功能
* 明确的隐私政策

---

## 9. 后端核心模块

### 9.1 模块划分

1. **Agent 配置管理**（静态 JSON / DB）
2. **任务创建与存储**
3. **Prompt 组装器**
4. **LLM 调用层**（OpenAI / Claude / Gemini 任一）
5. **结果持久化**
6. **错误处理与重试**

### 9.2 Prompt 组装逻辑

```text
System Prompt（角色定义）
↓
Workflow 规则（执行步骤）
↓
用户输入（表单数据）
↓
输出格式约束（JSON Schema）
```

### 9.3 LLM 调用策略

* **模型选择**：GPT-4o-mini（成本与效果平衡）
* **超时设置**：30 秒
* **重试机制**：失败后重试 1 次
* **降级策略**：主模型失败后切换备用模型
* **成本控制**：单次调用 token 限制在 4000 以内

---

## 10. 数据模型（简化版）

### Agent（数字员工）

```typescript
interface Agent {
  id: string;
  name: string;
  avatar: string;
  description: string;
  suitable_scenarios: string[];
  unsuitable_scenarios: string[];
  system_prompt: string;
  workflow_steps: string[];
  input_schema: JSONSchema;
  output_schema: JSONSchema;
  output_template: string;
  price_label: string;
  estimated_time: string;
  created_at: Date;
}
```

### Task（任务）

```typescript
interface Task {
  id: string;
  agent_id: string;
  session_id: string; // 用户标识
  input_data: Record<string, any>;
  output_data: Record<string, any> | null;
  status: 'pending' | 'processing' | 'completed' | 'failed';
  error_message?: string;
  created_at: Date;
  completed_at?: Date;
  execution_time?: number; // 毫秒
}
```

### Session（用户会话）

```typescript
interface Session {
  id: string;
  fingerprint: string;
  created_at: Date;
  last_active_at: Date;
}
```

---

## 11. 商业模式与定价

### 11.1 MVP 阶段定价策略

* **免费使用**：所有功能免费，但显示价格标签
* **目的**：验证用户对定价的接受度
* **数据收集**：记录用户对不同价格的反应

### 11.2 未来定价模型

#### 按次付费
* 商业分析师：¥9.9 / 次
* 文案助理：¥6.9 / 次
* 项目助理：¥8.9 / 次

#### 订阅制（后续）
* 基础版：¥29 / 月（30 次 / 月）
* 专业版：¥99 / 月（150 次 / 月）
* 企业版：定制

### 11.3 成本估算

* **LLM 成本**：约 ¥0.5-1.5 / 次（GPT-4o-mini）
* **服务器成本**：约 ¥500 / 月（初期）
* **目标毛利率**：70%+

---

## 12. 竞争分析与差异化

### 12.1 竞品对比

| 产品 | 定位 | 优势 | 劣势 |
|------|------|------|------|
| ChatGPT | 通用对话 | 功能强大、用户多 | 需要调 Prompt、无标准交付 |
| Poe | AI 聚合平台 | 多模型选择 | 仍是聊天形式、无任务导向 |
| Coze | Agent 构建平台 | 可自定义 Agent | 门槛高、非外包心智 |

### 12.2 核心差异化

1. **心智模型不同**：外包任务 vs 聊天对话
2. **标准化交付**：结构化输出 vs 自由文本
3. **降低门槛**：无需懂 Prompt vs 需要调试
4. **明确定价**：按任务付费 vs 按订阅付费
5. **专业感**：像雇人 vs 像用工具

### 12.3 护城河（长期）

* 高质量的 Agent 库
* 用户任务数据积累
* 垂直领域深耕
* 社区与口碑

---

## 13. 市场策略

### 13.1 目标市场

* **一级市场**：独立开发者、创业者（5-10 万人）
* **二级市场**：产品经理、市场人员（20-50 万人）
* **三级市场**：中小企业主（100 万+）

### 13.2 获客渠道

#### MVP 阶段
* **社交媒体**：Twitter / 即刻 / 小红书
* **社区**：V2EX / 掘金 / Product Hunt
* **内容营销**：发布使用案例、对比文章
* **口碑传播**：邀请早期用户试用

#### 后续
* SEO 优化
* 付费广告
* KOL 合作
* 联盟营销

### 13.3 增长指标

* **北极星指标**：完成任务数
* **关键指标**：
  * 周活跃用户数
  * 任务完成率
  * 用户留存率（D7 / D30）
  * 重复使用率

---

## 14. 风险评估与应对

### 14.1 核心风险矩阵

| 风险 | 概率 | 影响 | 应对策略 |
|------|------|------|---------|
| LLM 输出质量不稳定 | 高 | 高 | 严格的 Prompt 工程 + 输出验证 + 重试机制 |
| 用户不理解「外包」概念 | 中 | 高 | 清晰的引导 + 示例 + 教育内容 |
| 成本超出预期 | 中 | 中 | Token 限制 + 模型选择 + 缓存策略 |
| 竞品快速跟进 | 中 | 中 | 快速迭代 + 垂直深耕 + 社区建设 |
| 技术故障影响体验 | 低 | 高 | 监控告警 + 降级方案 + 错误处理 |

### 14.2 技术风险

* **LLM API 不稳定**：准备多个 LLM 提供商作为备份
* **响应时间过长**：优化 Prompt、使用更快的模型
* **数据安全问题**：加密存储、定期备份

### 14.3 业务风险

* **用户付费意愿低**：先验证价值，再考虑收费
* **获客成本高**：依靠口碑和内容营销
* **留存率低**：提升 Agent 质量、增加使用场景

---

## 15. 验收标准

### 15.1 功能验收

- [ ] 用户可以浏览所有数字员工
- [ ] 用户可以查看数字员工详情（能力、价格、示例）
- [ ] 用户可以提交任务（表单验证正常）
- [ ] 用户可以看到任务执行进度
- [ ] 用户可以查看结构化结果
- [ ] 用户可以复制 / 下载结果
- [ ] 用户可以查看任务历史
- [ ] 错误情况有友好提示

### 15.2 性能验收

- [ ] 首页加载时间 < 2 秒
- [ ] 任务提交响应 < 500ms
- [ ] AI 执行时间 < 30 秒（90% 情况）
- [ ] API 可用性 > 99%

### 15.3 体验验收

- [ ] 移动端适配良好
- [ ] 表单填写流畅（有示例、有验证）
- [ ] 结果展示清晰（结构化、可复制）
- [ ] 错误提示友好（不出现技术术语）

---

## 16. 测试策略

### 16.1 测试类型

#### 单元测试
* Prompt 组装逻辑
* 数据验证逻辑
* 工具函数

#### 集成测试
* API 端到端测试
* LLM 调用测试（Mock）
* 数据库操作测试

#### 用户测试
* 5-10 个真实用户试用
* 观察完整使用流程
* 收集反馈和痛点

### 16.2 测试重点

* **Prompt 质量**：输出是否符合预期
* **边界情况**：异常输入、网络错误、超时
* **性能压力**：并发请求、大量数据
* **用户体验**：是否符合「外包」心智

---

## 17. 部署与发布

### 17.1 部署架构

* **前端**：Vercel（自动部署、CDN 加速）
* **后端**：Railway / Render（容器化部署）
* **数据库**：Supabase / Railway PostgreSQL
* **缓存**：Upstash Redis

### 17.2 发布流程

1. **内测**：邀请 10-20 个种子用户
2. **公测**：发布到社交媒体和社区
3. **收集反馈**：快速迭代 1-2 周
4. **正式发布**：Product Hunt / Hacker News

### 17.3 监控指标

* **技术指标**：API 响应时间、错误率、可用性
* **业务指标**：DAU、任务完成数、留存率
* **成本指标**：LLM 调用次数、Token 消耗

---

## 18. 发布前检查清单

### 18.1 功能检查
- [ ] 所有核心功能正常运行
- [ ] 3 个数字员工配置完成
- [ ] 所有 API 端点测试通过
- [ ] 错误处理机制完善

### 18.2 内容检查
- [ ] 文案无错别字
- [ ] 示例数据真实可用
- [ ] 隐私政策和用户协议
- [ ] 帮助文档 / FAQ

### 18.3 技术检查
- [ ] 生产环境配置正确
- [ ] 数据库备份机制
- [ ] 监控和告警配置
- [ ] 日志记录完善

### 18.4 体验检查
- [ ] 移动端测试通过
- [ ] 多浏览器兼容性测试
- [ ] 加载速度优化
- [ ] SEO 基础优化

---

## 19. 成功指标（MVP 验证用）

### 19.1 定量指标

* **使用指标**：
  * 7 天内获得 100+ 独立用户
  * 任务完成数 > 200
  * 任务完成率 > 85%
* **留存指标**：
  * D7 留存率 > 20%
  * 重复使用率 > 30%
* **体验指标**：
  * 平均任务完成时间 < 25 秒
  * 用户满意度 > 4.0 / 5.0

### 19.2 定性指标

* 用户反馈中是否出现：
  * "这个比我自己问 AI 省事"
  * "输出很标准，可以直接用"
  * "我会推荐给朋友"
* 是否有人重复使用同一个数字员工
* 是否有人主动分享到社交媒体

### 19.3 失败信号

* 用户流失在「任务提交」环节 > 50%
* 用户反馈「还不如直接用 ChatGPT」
* 重复使用率 < 10%

---

## 20. 开发节奏建议

### 20.1 时间规划（8 天）

* **Day 1-2**：Agent 定义 + Prompt 工程
  * 完成 3 个数字员工的 Prompt
  * 测试输出质量
* **Day 3-5**：后端基础 + LLM 调用
  * 搭建 API 框架
  * 实现核心业务逻辑
  * 集成 LLM
* **Day 6-7**：前端 3 页面
  * 首页 + 任务提交页 + 结果页
  * 响应式适配
* **Day 8**：真实用户测试
  * 邀请 5-10 个用户试用
  * 收集反馈并快速修复

### 20.2 里程碑

* **M1**：后端 API 可用（Day 5）
* **M2**：前端基础完成（Day 7）
* **M3**：内测版本发布（Day 8）
* **M4**：公开发布（Day 10-12）

---

## 21. 后续迭代方向（不做但要想清楚）

### 21.1 短期迭代（1-3 个月）

* 增加更多垂直领域的数字员工（5-10 个）
* 优化 Prompt 和输出质量
* 增加用户账号系统
* 支持任务历史和收藏

### 21.2 中期迭代（3-6 个月）

* 用户自定义数字员工
* 数字员工市场（上架、评分、分成）
* 多任务队列 / 异步执行
* 支付集成

### 21.3 长期愿景（6-12 个月）

* 组织 / 团队模式
* API 开放平台
* 企业定制服务
* 垂直行业解决方案

---

## 22. 附录

### 22.1 关键术语

* **数字员工**：预配置的 AI Agent，具有特定能力和输出格式
* **任务**：用户提交给数字员工的具体工作需求
* **交付物**：数字员工完成任务后的结构化输出
* **外包心智**：用户把任务「交出去」而非「对话式探索」的心理模型

### 22.2 参考资源

* OpenAI API 文档
* Anthropic Claude API 文档
* Next.js 文档
* Prisma 文档

---

> **MVP 判断标准：**
> 不是"像不像平台"，而是"像不像真的能外包活"。
>
> **核心验证问题：**
> 用户是否愿意为「标准化的 AI 劳务」付费？
